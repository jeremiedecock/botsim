TODO

Exemple de qualité physique et visuelle à atteindre: https://www.youtube.com/watch?v=BGAwRKPlpCw

x Utiliser eigen pour les vecteur donnés aux constructeurs des Objets
x MSAA
x Black background
x Light (directional ?)
x Ajouter et utiliser asseseurs dans Objects
x Ajouter des fonctions wrapper vec3_eigen_to_bullet, ...
x Renommer Objects -> Parts
x Séparer les modules
x Ombres
x Caméra
x Ajouter les fichiers AUTHORS et COPYING
x Remplacer le makefile par un cmakelist -> Créer une arborescence et des modules .h/.cpp
x Ajouter des matériaux pour les objets "Part"

- Key reset -> ajouter une méthode "reset()" dans "BulletEnvironment"
x Key print camera coordinates
x Key take screenshot
x Key start/stop recording -> screencast
x Add OSG fog

x Doxygen
x Permettre de configurer le refresh rate ou de passer en mode "temps réel" (-1)
x Améliorer le réalisme des simulations physiques
x Renommer le répertoire "simulation" -> "scenes"
  adapter le cmakelist pour créer plusieurs scenes co. ds metis (chaque scene = 1 exe)
+ Exporter un fichier stat (dat ou json ?)
  -> classe Log qui utilise le pattern Observateur (+ s'inspirer des logs de metis)
     x Part = sujet
       LogJson / LogDat = observateur
     x faire un snippet C++
       snippets/cpp/designpatterns/doxyfile
                                   listener
                                       subject.cpp
                                       listener.cpp
                                   singleton
                                       ...
                                   ...
  -> systeme de log générique comme pour metis:
     - Simulation time, User time, Time step, Fixed sub time step, Sub steps, Max sub steps + FPS
     x Forces, accélérations, vitesse, position, énergie, ... des Parts
     - Forces, accélérations, vitesse, position, énergie, ... des Objets
- get OSG FPS
x Permettre de lancer une simulation sans interface graphique (sans osg)
  ajouter une méthode run(time) dans BulletEnvironment qui ne fait qu'appeler autant de fois que nécessaire this->stepSimulation()
  cette fonction membre doit prendre en paramètre le temps que doit durer la simulation (utiliser boost pour transmettre cette valeur à l'appel de l'executable (~=getopt))
+ Vérifier le code physique, ...
+ Classe Object qui contient un vecteur de Parts et un vecteur de "Joint" (une simple paire de "Part" (référence ou pointeur de "Part" ?) + les axes de libertés)
x Ajouter le "part" sphere (ou ball ?)
x Ajouter une scene avec seulement une sphere qui tombe pour vérifier les logs
- boost::Program_options:
  - set OSG resolution
  - set OSG FSAA on/off
  - set OSG shadow on/off
  - set OSG gauraud shading on/off

- Servomoteurs: classe "Actuator" qui hérite de la classe "Hinge"
  btHingeConstraint.enableAngularMotor(...)
- Screencast : ajouter un option pour permettre de capturer les images à un framerate constant (de 25fps).
  créer une classe fille de osgViewer::ScreenCaptureHandler::WriteToFile avec un compteur de temps (attention: pas le temps réel mais le temps de la simulation)...
  ou + simple, cf. src/osgViewer/Viewer.cpp "--run-max-frame-rate" ("frame rate capping")
     https://groups.google.com/forum/#!topic/osg-users/MgMCDb2qv4c
     http://forum.openscenegraph.org/viewtopic.php?t=2364
     http://alphapixel.com/content/what-are-all-openscenegraph-environment-variables
     http://comments.gmane.org/gmane.comp.graphics.openscenegraph.user/58547

x Part est une classe abstraite, elle ne devrait pas pouvoir être instanciée -> au moins une fonction virtuelle pure (constructeur ?)
x Assesseurs pour les attributs des objets "Part", "BulletEnvironment" et "OSGEnvironment"
  -> Ajouter des assesseurs pour les propriétés physiques des objets "Part", "BulletEnvironment"
x Fonctions virtuelles pures dans Parts et Objects (Part et Object ne devraient pas être instanciables)
+ Renommer correctement les variables (p_...) + utiliser les smart pointers sur tous les objets OSG + détruire correctement les autre objets
+ check memleak with Valgrind + check code with lint-like static analysers (cppcheck, llvm, ...)
- Scale units factor (mm ?, kg ?, ...)
+ Compléter la doc en ligne (doxygen)

- Ajouter des objets: sphere, cylindre, etc. + faire des démos
- Objets STL (balle de golf, charnières 1DOF, charnières 2DOF, ...) + ceiling + faire des démos

+ set custom restitution, static and kinetic friction per objects
  http://stackoverflow.com/questions/8289653/bouncing-ball-in-bullet
  http://bulletphysics.org/Bullet/phpBB3/viewtopic.php?t=6783
  see also blender physics part.

- transférer les commits vers l'autre référentiel git et marquer version 2.0pre1
- changer de licence ? (GPL ? CeCILL ? ou MIT ?)

- Afficher les vecteurs force, etc. ac. OSG

- Senseurs -> créer une interface (ou une classe abstraite) "Sensor"
  -> accéléromètre (facile ?)
  -> position absolue/pseudo GPS (facile ?)
  -> odomètre (facile ?)
  -> gyroscope (facile ?)
  -> position angulaire des actuateurs (facile ?)
  -> caméra (difficile ?)
  -> capteurs de force/de contact/de pression (difficile ?)
  -> capteur de distance IR/ultrasons (difficile ?)
- Permettre de sauvegarder les données des senseurs (au format JSON ?) -> appliquer le pattern listener sur les hinge et actuators
- Créer un OSG_Bullet_Qt_Lab pour tester interactivement les propriétés physique des objets et du simulateur (des widgets permettent de "voir" immédiatement l'impact sur la simulation de la modification de certains paramètres)
  -> charnières: impulsions, mesure du couple appliqué, mesure de l'énergie donné en entrée/dissipée/etc., résistance, autres forces (centrifuge, ...)
  -> friction, frottements, ...
  -> énergie des objets (cinétique, potentielle, ...) + forces appliquées
  -> absorption/restitution de l'énergie lors des chocs
  -> soft bodies
  -> mesurer les vraies propriétés physique des charnières et des servo moteurs, les retranscrire sur les modèles numériques et comparer les simulations à la réalité sur des objets simples
  -> ...
- Vérifier à la main une simulation simple (calculer à la main l'équation d'un objet qui tombe et comparer avec bullet)
- Contrôleurs: classe "Controler" -> pattern listener : écoute les sensors et agit sur les actuators
  -> + permettre le contrôle des actuateurs depuis un processus distant ? (socket, rpc, ...)
- Créer une classe "Noise" appliquée aux senseurs/aux actuateurs pour simuler la transposition à la réalité -> pattern wrapper ?

- Améliorer le rendu graphique: régler correctement les matériaux
  => faire une appli dédiée OSG_Qt_Lab (ex: http://www.it.hiof.no/~borres/j3d/explain/light/p-mated.html )
  + improve shadow technics ( http://trac.openscenegraph.org/projects/osg//wiki/Support/ProgrammingGuide/osgShadow )
- Faire des vidéos et les poster sur jdhp

Copier dans BOTSIM v2.0:
-> Créer des contrôleurs
   -> SAES + sinusoïdes
   -> SAES + convolution de sinusoïdes
   -> SAES + neural net (?)
   -> PID (pendule inversé)
   -> Reinforcement learning
   -> Contrôle manuel via un joypad (pour les robots à roues)
-> Modéliser, créer les objets et créer les contrôleurs pour des robots
   -> Créer un robot à 4 roues
   -> Créer un robot à 2 roues (pendule inversé)
   -> Créer un robot à 4 pattes
   -> Créer un robot à 6 ou 8 pattes
-> Optimisation les contrôleurs -> quelle "interface" dans l'API ?
   -> Permettre d'optimiser les contrôleurs de manière répartie (MPI, OpenMP, ...)

- Améliorer le rendu: fog + LOD
- Améliorer le rendu: GLSL (shaders)
- Améliorer le rendu: motion blur

- Utiliser d'autres moteurs de rendu => créer une couche d'abstraction neutre pour la partie graphique de botsim:
  - luxrender : directement via l'api C ou via l'export de fichiers scene luxrender (ascii) pour un rendu "offline"
                http://www.luxrender.net/en_GB/developer_api
                http://www.luxrender.net/wiki/API_Usage_example
                http://www.luxrender.net/wiki/LuxCore
                http://www.luxrender.net/wiki/Scene_file_format#Introduction
                http://www.luxrender.net/wiki/Frequently_Asked_Questions
                http://www.luxrender.net/wiki/LuxRays
                http://www.luxrender.net/wiki/Main_Page
    d'importer les fichiers STL (ce que ne semble pas faire Yafaray et ce que
    Povray ne peut faire qu'à l'aide d'un outil externe...): http://www.luxrender.net/wiki/New_in_0-8 .
  - sunflow : http://sunflow.sourceforge.net/index.php?pg=feat
  - PBRT : http://www.pbrt.org/index.php
  - yafaray : directement via l'api C++ (ne semble pas vraiment prévu pour ?)
              ou via l'export de fichiers scene yafaray XML pour un rendu "offline"
              http://www.yafaray.org/documentation/userguide
              http://www.yafaray.org/documentation/tutorials
  - povray : directement via l'api C++ (ne semble pas vraiment prévu pour ?) ou
             via l'export de fichiers scene PovRay (ascii) pour un rendu "offline"
  À priori, luxrender est à privilégier, il dispose bien d'une
  API conçue pour faciliter l'intégration à d'autres projets et permet
  en plus d'importer des fichiers STL.
  Sunflow et PovRay sont les seuls disponibles directement dans Debian Jessie.
  En revanche, le développement de sunflow est arrêté depuis 2008 ! (le dernier
  commit date de 2008 et le site web n'a pas été mis à jours depuis 2007)
  À noter aussi que sunflow est écrit en Java et non en C++ et son API semble
  tournée uniquement vers Java.
  => nécessite de distinguer:
     - le rendu temps réel "à l'écran" (OpenGL, OSG, ...) => la boucle
       principale est dans l'API graphique (osgenvironment.run() par exemple) +
       callback pour le moteur physique à chaque frame
     - le rendu offline "sur fichiers" (luxrender, yafaray, povray, OSG(?),
       blender, ...) => la boucle principale est dans l'API physique
       (bulletenvironment.run()) + implémenter un callback pour le moteur de
       rendu à chaque "timestep"
         => distinguer également:
            - le rendu *d'images* offline (luxrender, yafaray, povray, ...)
            - l'export *de scenes* (fichiers texte) offline (luxrender, yafaray, povray, ...)
  => il faut déléguer le rendu de chaque part (material, textures, ...) dans
     des méthodes à appeler dans le callback de rendu. Pour permettre le rendu
     d'une instance d'une classe fille de "Part", la classe correspondant doit
     implémenter l'interface "PartX" avec "X" le nom du moteur (ex: "Box" doit
     implémenter "PartPovray" pour être rendu avec Povray, "PartOSG" pour être
     rendu dans OSG, ...). => permet de supprimer toute dépendance à OSG dans le
     module "Part".  Ces interfaces ("PartOSG", "PartPovray", ...) déclarent une
     seul méthode (appelée par le callback de rendu).
     Seul le maillage de la pièce (un fichier STL) est commun à tous les moteurs
     de rendu et donc défini directement dans "Part" => ça permet de pouvoir
     faire quand même un rendu de "Box" avec OSG (par exemple) même s'il
     n'implémente pas l'interface "PartOSG": seules les les textures,
     matérials, etc. seront ignorées (car non défini pour le moteur de
     rendu utilisé...).

- Rendu offline avec Blender:
  il y a une API en Python mais pas en C/C++ ("Blender n'est pas une librairie") cf. http://www.blender.org/forum/viewtopic.php?t=27482&sid=b6f1c87a8c54ca3d3b24eea7787efc0c .
  L'API python:
  - Old <= 2.49
  - New >= 2.5
  Les 2 versions (old / new) sont incompatibles.
  Execution d'un script python blender sans lancer l'interface blender : option "--background"
     http://www.blender.org/api/blender_python_api_2_61_0/info_tips_and_tricks.html#don-t-use-blender 
     http://wiki.blender.org/index.php/Doc:2.6/Manual/Render/Command_Line
     blender --background --python myscript.py
     ou
     blender myscene.blend --background --python myscript.py
  Render and saving images:
     http://stackoverflow.com/questions/14982836/rendering-and-saving-images-through-blender-python
     bpy.data.scenes['Scene'].render.filepath = '/home/user/Documents/image.jpg'
     bpy.ops.render.render( write_still=True )

     http://wiki.blender.org/index.php/Dev:2.5/Py/Scripts/Cookbook/Code_snippets/World_view_renderer
     render = bpy.context.scene.render
     render.resolution_x = 720
     render.resolution_y = 576
     render.resolution_percentage = 100
     render.fps = 24    
     render.use_raytrace = False
     render.use_color_management = True
     render.use_sss = False
  Create objects:
     http://wiki.blender.org/index.php/Dev:2.5/Py/Scripts/Cookbook/Code_snippets/Three_ways_to_create_objects
  Manual http://wiki.blender.org/index.php/Doc:2.6/Manual/Extensions/Python
         http://www.blender.org/api/blender_python_api_2_74_0/
  Import STL files: http://stackoverflow.com/questions/25083566/import-stl-script-blender
     bpy.ops.import_mesh.stl(filepath="C://Users//Dom//Documents//DomCorp.//mymodel.stl", filter_glob="*.stl",  files=[{"name":"mymodel.stl", "name":"mymodel.stl"}], directory="C://Users//Dom//Documents//DomCorp.")

- Singleton OSG / Bullet ? -> bof...
- Txt infos (hinge constraints, ...)

- Permettre aux objets "Part", etc. d'être chargés dynamiquement sous la forme de plugins
  -> objets décrits en XML 
- Faire une interface graphique pour construire les robots, lancer les simulations et récupérer les résultats interactivement (ie rendre le logiciel utilisable pour le "grand public")
  -> robots décrits en XML (format de sauvegarde)

